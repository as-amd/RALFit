\documentclass{spec}

\usepackage{amsfonts,bm,amsmath}
\usepackage{verbatim}
% set the release and package names

\newcommand{\libraryname}{RAL}
\newcommand{\packagename}{NLLS}
\newcommand{\fullpackagename}{\libraryname\_\packagename}
\newcommand{\versionum}{0.5.0}
\newcommand{\versiondate}{15 January 2016}
\newcommand{\version}{\versionum}
\newcommand{\vx}{ {\bm x} } % macro for a vector x
\newcommand{\vr}{ {\bm r} } % macro for a vector r
\newcommand{\vg}{ {\bm g} } % macro for a vector g
\newcommand{\vd}{ {\bm d} } % macro for a vector d
\newcommand{\vH}{ {\bm H} } % macro for a matrix H
\newcommand{\vJ}{ {\bm J} } % macro for a matrix J
\newcommand{\iter}[2][k]{ #2_{#1}^{}} % macro for an iteration
\newcommand{\comp}[2][i]{ #2_{#1}^{}} % macro for a component of a vector
\begin{document}

\hslheader

\begin{center}
\huge \sc  C Interface
\end{center}

\hslsummary
{\tt \fullpackagename} computes a solution to the non-linear least-squares problem
\begin{equation}
\min_\vx \  F(\vx) := \frac{1}{2}\| \vr(\vx) \|_2^2,
\label{eq:nlls_problem}
\end{equation}
where $\vr(\vx) =(\comp[1]{r}(\vx), \comp[2]{r}(\vx),...,\comp[m]{r}(\vx))^T$ is the non-linear residual of
some data that needs fitting.
% the fit of the data $y$ to some non-linear function ${\bm f} : \mathbb{R}^n \rightarrow \mathbb{R}^m$
% ($m>n$).
% The $n$ variables that are fitted are $\vx=(x_1,x_2,...,x_n)^T$.
% \textcolor{blue}{Some confusion: the $y_i$ don't appear again.}

The algorithm is iterative.
At each point, $\iter{\vx}$, a quadratic model of the function
\[
F(\iter{\vx}) \approx \iter{m}(\vx) := {\iter{\vg}}^T \vx + \frac{1}{2} {\vx}^T \iter{\vH} \vx.
\]
is built.
The `ideal' values in this model are $\iter{\vg} = {\iter{\vJ}}^T\vr(\iter{\vx})$ and
$\iter{\vH} = {\iter{\vJ}}^T\iter{\vJ} + \sum_{i = 1}^m \comp{r}(\iter{\vx}) \nabla^2 \comp{r}(\iter{\vx})$,
where $\iter{\vJ}$ denotes the $m \times n$ Jacobian of $\vr(\vx)$ at the point $\iter{\vx}$
and $\iter{\vH}$ is the Hessian at $\iter{\vx}$.

Once the model has been formed, a trust-region sub-problem of the form
\[
\vd = \arg \min_{\vx} \ \iter{m} (\vx) \quad \mathrm{s.t.} \quad  \|\vx\|_B \leq \Delta,
\]
is solved,
where $\Delta$ is the trust region radius and $B$ is a given symmetric positive definite matrix.
The quantity
\[\rho = \frac{F(\iter{\vx}) - F(\iter{\vx} + \vd)}{\iter{m}(\iter{\vx}) - \iter{m}(\iter{\vx} + \vd)}\]
is then calculated.
If this is sufficiently large, the point is accepted and  $\iter[k+1]{\vx}$ is set to $\iter{\vx} + \vd$; if not, the trust-region radius, $\Delta$,
is reduced and  the resulting new trust-region sub-problem is solved.  If the step is very successful -- in that $\rho$ is close to one --
the trust-region radius is increased.

This process continues until either the residual, $\|\vr(\iter{\vx})\|_2$, or a measure of the gradient,
$\|{\iter{\vJ}}^T\vr(\iter{\vx})\|_2 / \|\vr(\iter{\vx})\|_2$, is sufficiently small.


%!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\hslattributes
\hslversions{\versionum\ (\versiondate)}.
\hslIRDCZ Real (single, double).
\hsllanguage Fortran 2003 subset (F95+TR155581).
\hsldate January 2016.
\hslorigin The Numerical Analysis Group, Rutherford Appleton Laboratory.
\hslremark The development of this package was
partially supported by EPSRC grant EP/M025179/1.

%!!!!!!!!!!!!!!!!!!!!!!!!!!!
\newpage
\hslhowto

\subsection{Calling sequences}

Functions signatures are defined in a header file
\begin{verbatim}
   #include "ral_nlls.h"
\end{verbatim}
\medskip

\noindent The user callable subroutines are:
\vspace{-0.1cm}
\begin{description}
   \item[\texttt{ral\_nlls\_default\_options()}] initializes solver options to default values.
   \item[\texttt{ral\_nlls()}]  solves the non-linear least squares problem (Section~\ref{eq:nlls_problem}).
   \item[\texttt{ral\_nlls\_init\_workspace()}] initialises a workspace for use with \texttt{ral\_nlls\_iterate()}.
   \item[\texttt{ral\_nlls\_iterate()}] performs a single iteration of the solver algorithm.
   \item[\texttt{ral\_nlls\_free\_workspace()}] frees memory allocated by a call to \texttt{ral\_nlls\_init\_workspace()}.
\end{description}

%%%%%%%%%%%%%%%%%%%%%% derived types %%%%%%%%%%%%%%%%%%%%%%%%

\hsltypes
\label{derived types}
For each problem, the user must employ the derived types defined by the
module to declare scalars of the types {\tt struct ral\_nlls\_options}, and
{\tt ral\_nlls\_inform}.
The following pseudocode illustrates this.
\begin{verbatim}
   #include "ral_nlls.h"
   ...
   struct ral_nlls_options options;
   struct ral_nlls_inform info;
   ...
\end{verbatim}
The members of these structs are explained
in Sections~\ref{typeoptions} and \ref{typeinform}.


%%%%%%%%%%%%%%%%%%%%%% argument lists %%%%%%%%%%%%%%%%%%%%%%%%
\hslarguments

\subsubsection{Integer and package types}
%{\tt INTEGER} denotes default {\tt INTEGER} and
%{\tt INTEGER(long)} denotes {\tt INTEGER(kind=selected\_int\_kind(18))}.
The term {\bf package type} is used to mean \texttt{float}
if the single precision version is being used and
\texttt{double} for the double precision version.

\subsubsection{To initialise members of \texttt{struct nlls\_options} to default values}

To initialise the value of \texttt{struct nlls\_options}, the user \textbf{must} make a
call to the following suboutine (failure to do so will result in undefined behaviour):
\begin{verbatim}
   void ral_nlls_default_options(struct ral_nlls_options *options);
\end{verbatim}

\begin{description}
   \itt{*options} will be initialised to default values on return.
\end{description}

\subsubsection{To solve the non-linear least squares problem}
\label{sec:solve}

To solve the non-linear least squares problem make a call of the following
subroutine:

\begin{verbatim}
   void ral_nlls( int n, int m, double X[], ral_nlls_eval_r_type eval_r,
      ral_nlls_eval_j_type eval_j, ral_nlls_eval_hf_type eval_hf,
      void* params, struct nlls_inform* status, struct nlls_options const* options)
\end{verbatim}

\begin{description}
\itt{n} holds the number $n$ of
variables to be fitted; i.e., $n$ is the length of the unknown vector $\bm x$.

\itt{m} holds the number $m$ of
data points available; i.e., $m$ is the number of functions $f_i$.
\textbf{Restriction:} \texttt{m},\texttt{n}$>$\texttt{0}

\itt{x} must hold the initial guess for $\bm x$, and on
successful exit it holds the solution to the non-linear least squares problem.

\itt{eval\_r} specifies a callback function that, given a point $\iter{\vx}$,
returns the vector $\vr(\iter{\vx})$. Details of the function signature and
requirements are are given in Section~\ref{sec::function_eval}.

\itt{eval\_j} specifies a callback function that, given a point $\iter{\vx}$,
returns the $m \times n$ Jacobian matrix, $\iter{\vJ}$, of $\vr$ at $\iter{\vx}$. Details of the function signature and requirements are are given in
Section~\ref{sec::function_eval}.

\itt{eval\_hf} is a {\tt PROCEDURE} that, given a point $\iter{\vx}$
and function $\vr(\iter{\vx})$, returns the second-order terms of the Hessian at $\iter{\vx}$.
Further details of the format required are given in Section~\ref{sec::function_eval}.

\itt{params} is a pointer to user data that is passed unaltered to the callback
functions {\tt eval\_r}, {\tt eval\_J}, and {\tt eval\_Hf}.

\itt{info} provides information about the execution
of the subroutine, as explained in Section~\ref{typeinform}.

\itt{options} specifies options that control the execution of the subroutine,
see Section~\ref{typeoptions}.

\end{description}

\subsubsection{To initialise a workspace for use with \texttt{ral\_nlls\_iterate()}}

Prior to the first call of \texttt{ral\_nlls\_iterate()}, the workspace must be
initialised by a call to the following subroutine:
\begin{verbatim}
   void ral_nlls_init_workspace(void **workspace);
\end{verbatim}

\begin{description}
   \itt{*workspace} will, on return, be allocated and initialised using Fortran intrinsics.
      To avoid a memory leak, it must be freed through a call to \texttt{ral\_nlls\_free\_workspace()}.
\end{description}

\subsection{To iterate once}
\label{sec:iterate}
Alternatively, the user may step through the solution process one iteration at
a time by making a call of the following form:

\begin{verbatim}
   void ral_nlls_iterate( int n, int m, double X[], ral_nlls_eval_r_type eval_r,
      ral_nlls_eval_j_type eval_j, ral_nlls_eval_hf_type eval_hf,
      void* params, struct nlls_inform* status, struct nlls_options const* options,
      void* workspace)
\end{verbatim}

\begin{description}

\item[\normalfont \texttt{n}, \texttt{m}, \texttt{eval\_F}, \texttt{eval\_J}, \texttt{eval\_HF}, \texttt{params}, \texttt{info} and \texttt{options}] are as described in Section~\ref{sec:solve}.

\itt{X} is an array of size {\tt n}. On the first call, it must hold the initial guess for
$\bm x$. On return it holds the value of $\bm x$ at the current iterate, and
must be passed unaltered to any subsequent call to \texttt{ral\_nlls\_iterate()}.

\itt{w} is workspace allocated and initialised through a previous call to
\texttt{ral\_nlls\_init\_workspace()}.

\end{description}

\subsubsection{To free a workspace when it is no longer required}

Memory allocated during the call to \texttt{ral\_nlls\_init\_workspace()} may be freed
by a call to the following subroutine:
\begin{verbatim}
   void ral_nlls_free_workspace(void **workspace);
\end{verbatim}

\begin{description}
   \itt{*workspace} is the workspace to be freed. On exit it will be set to \texttt{NULL}.
\end{description}


\subsection{User-supplied function evaluation routines}
\label{sec::function_eval}
In order to evaluate the function, Jacobian and Hessian at a point, the user
must supply callback functions that perform this operation that the code
{\tt ral\_nlls} will call internally.

In order to pass user-defined data into the evaluation calls, the parameter
\texttt{params} is passed unaltered to the callback functions. Typically this
will be a pointer to a user defined structure that stores the data to be fitted.

\subsubsection{For evaluating the function $r(x)$}
A subroutine must be supplied to calculate $r(x)$ for a given vector $x$. It
must have the following signature:

\begin{verbatim}
   int eval_r (int n, int m, void const* params, double const* x, double* r);
\end{verbatim}

\begin{description}
   \itt{n, m, params} are passed unchanged as provided in the call to
      {\tt ral\_nlls}.

   \itt{x} holds the current point $\iter{\vx}$ at which to evaluate $\vr(\iter{\vx}$.

   \itt{r} must be set by the routine to hold the residual function
      evaluated at the current point $\iter{\vx}$, $\vr(\iter{\vx})$.
\end{description}
\textbf{Return value:} The function should return \texttt{0} on success. A
non-zero return value will cause the least squares fitting to abort with an
error code.


\subsubsection{For evaluating the function $J = \nabla \vr(\iter{\vx})$}
A subroutine must be supplied to calculate $J = \nabla \vr(\iter{\vx})$ for a given vector $x$. It must have the following signature:

\begin{verbatim}
   int eval_j (int n, int m, void const* params, double const* x, double* J);
\end{verbatim}

\begin{description}
   \itt{n, m, params} are passed unchanged as provided in the call to
      {\tt ral\_nlls}.

   \itt{x} holds the current point $\iter{\vx}$ at which to evaluate
      $J(\iter{\vx})$.

   \itt{J} must be set by the routine to hold the Jacobian of the residual
      function evaluated at the current point $\iter{\vx}$, $\vr(\iter{\vx})$.
      \texttt{J[i*m+j]} must be set to hold $\nabla_{x_j} r_i(\iter{\vx})$.
\end{description}
\textbf{Return value:} The function should return \texttt{0} on success. A
non-zero return value will cause the least squares fitting to abort with an
error code.

\subsubsection{For evaluating the function $HF = \sum_{i=1}^m \vr_i(x) \nabla^2 \vr_i(x)$}
A subroutine must be supplied to calculate $HF = \sum_{i=1}^m \vr_i(x) \nabla^2 \vr_i(x)$ for a given vector $x$. It must have the following signature

\begin{verbatim}
int eval_hf (int n, int m, void const* params, double const* x, double const* r, double* *HF);
\end{verbatim}

\begin{description}
   \itt{n, m, params} are passed unchanged as provided in the call to
      {\tt ral\_nlls}.

   \itt{x} holds the current point $\iter{\vx}$ at which to evaluate $rx)$.

   \itt{r} holds $\vr(x)$, as returned by a previous call to \texttt{eval\_r}.

   \itt{HF} must be set by the routine to holds the matrix
      $\sum_{i = 1}^m \comp{\vr}(\iter{\vx})\nabla^2\comp{\vr}(\iter{\vx})$, held
      by columns as a vector.
\end{description}
\textbf{Return value:} The function should return \texttt{0} on success. A
non-zero return value will cause the least squares fitting to abort with an
error code.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{The options derived data type}
\label{typeoptions}

The structure of type {\tt struct ral\_nlls\_options} is used to hold
controlling data. The components must be initialised through a call to
\texttt{ral\_nlls\_default\_options()}.

\vspace{2mm}

\noindent {\bf Components that control printing}
\begin{description}

\itt{int error} with default value {\tt 6}
is used as the Fortran unit number for error messages. If it is negative, these
messages will be suppressed.

\itt{int out} with default value {\tt 6}
is used as the Fortran unit number for general messages. If it is negative, these messages will be suppressed.

\itt{int print\_level} with default value {\tt 0} that
controls the level of output required.
\begin{description}
\item{\tt $\leq$ 0} No informational output will occur.
\item{\tt = 1} As 0, plus gives a one-line summary for each iteration.
\item{\tt = 2} As 1, plus gives a summary of the inner iteration for each iteration.
\item{\tt > 3} As 3, and gives increasingly verbose (debugging) output.
\end{description}
The default is {\tt diagnostics\_level} $=$ 0.
\end{description}

\noindent {\bf Components that control the main iteration}.

\begin{description}

\itt{int maxit} gives an upper bound on the number
of iterations the algorithm is allowed to take before being stopped.  The default value is {\tt 100}.

\itt{int model} specifies the model, $m_k(\cdot)$, used.  Possible values are
\begin{description}
  \item{\tt 1} Gauss-Newton (no Hessian).
  \item{\tt 2} Newton (exact Hessian).
%  \item{\tt 3} Barely second-order (Hessian matrix approximated by the identity).
  \item{\tt 9} Hybrid method (mixture of Gauss-Newton/Newton as appropriate).
\end{description}
The default is {\tt model = 1}.

\itt{int nlls\_method} specifies the method used to solve
(or approximate the solution to) the trust-region sub problem.  Possible values are
\begin{description}
  \item{\tt 1} Powell's dogleg method (approximates the solution).
  \item{\tt 2} The Adachi-Iwata-Nakatsukasa-Takeda (AINT) method.
  \item{\tt 3} The More-Sorensen method.
  \item{\tt 4} Galahad's DTRS method
\end{description}
The default is {\tt nlls\_method = 1}.

\itt{double stop\_g\_absolute} specifies the absolute tolerance for convergence.

\itt{double stop\_g\_relative} specifies the relative tolerance for convergence.

\itt{double relative\_tr\_radius} specifies whether the initial trust region
radius should be scaled.

\itt{double initial\_radius\_scale} specifies the scaling parameter for the initial trust region radius, which is only used if {\tt relative\_tr\_radius = 1}.

\itt{double initial\_radius} specifies the initial trust-region radius, $\Delta$.

\itt{double maximum\_radius} specifies the maximum size permitted for the trust-region radius.

\itt{double eta\_successful} specifies the smallest value of $\rho$ such that we accept the step.

\itt{double eta\_very\_successful} specifies the value of $\rho$ after which we increase the trust-region radius.

\itt{double eta\_too\_successful} specifies that value of $\rho$ after which we accept the step,
but keep the trust-region radius unchanged.

\itt{double radius\_increase} specifies the factor to increase the trust-region radius by.

\itt{double radius\_reduce} specifies the factor to decrease the trust-region radius by.

\itt{double hybrid\_switch} specifies the value, if {\tt nlls\_method = 9},
at which we switch to second derivatives.

\itt{bool exact\_second\_derivatives} if {\tt true}, signifies that the
exact second derivatives are available (and, if {\tt false}, approximates them using a secant method).

\itt{int more\_sorensen\_maxits} if {\tt nlls\_method = 3}, specifies the maximum number of iterations allowed in the More-Sorensen method.

\itt{double more\_sorensen\_shift} if {\tt nlls\_method = 3}, specifies the shift to be used in the More-Sorensen method.

\itt{double more\_sorensen\_tiny} if {\tt nlls\_method = 3}, specifies the value
below which we consider numbers to be essentially zero.

\itt{double more\_sorensen\_tol} if {\tt nlls\_method = 3}, specifies the tolerance
to be used in the More-Sorensen method.

\itt{double hybrid\_tol} if \(\|J^T f \| < \mathtt{hybrid\_tol} * 0.5 \|f\|^2\), switches to a (quasi-)Newton method.

\itt{int hybrid\_switch\_its} sets how many iterates in a row must
the condition in the definition of {\tt hybrid\_tol} hold before a switch.

\itt{bool output\_progress\_vectors} if true, outputs the progress vectors at the end of the routine.

\end{description}


\subsection{The derived data type for holding information}
\label{typeinform}
The structure of type {\tt struct ral\_nlls\_inform} is used
to hold information from the execution of {\tt ral\_nlls}.
The members are:
\begin{description}
\itt{int status} gives the exit status of the subroutine.  See Section~\ref{hslerrors} for details.
\itt{int alloc\_status} gives the status of the last attempted allocation/deallocation.
\itt{int iter} gives the total number of iterations performed.
\itt{int f\_eval} gives the total number of evaluations of the objective function.
\itt{int g\_eval} gives the total number of evaluations of the gradient of the objective function.
\itt{int h\_eval} gives the total number of evaluations of the Hessian of the objective function.
\itt{int convergence\_normf} tells us if the test on the size of \(f\) is satisfied.
\itt{int convergence\_normg} tells us if the test on the size of the gradient is satisfied.
%\itt{double *resvec} holds the vector of residuals
%\itt{double *gradvec} holds the vector of gradients.
\itt{double obj} holds the value of the objective function at the best estimate of the solution determined by the algorithm.
\itt{double norm\_g} holds the gradient of the objective function at the best estimate of the solution determined by the algorithm.
\end{description}

%%%%%%%%%%%%%%%%%%%%%% Warning and error messages %%%%%%%%%%%%%%%%%%%%%%%%

\hslerrors

A successful return from a subroutine in the package is indicated by
{\tt info.status} having the value zero.
A non-zero value is associated with an error message that by default will
be output on the Fortran unit {\tt info.error}.

Possible values are:
\begin{description}
\item{} {\tt -1} Maximum number of iterations reached without convergence.
\item{} {\tt -2} Error from evaluating a function/Jacobian/Hessian.
\item{} {\tt -3} Unsupported choice of model.
\item{} {\tt -4} Error return from an {\tt lapack} routine.
\end{description}

\hslgeneral

\hslrestrictions {\tt m$\ge$n$\ge$1}.

\hslmethod
\label{method}

% todo!

\hslexample
Consider fitting the function $y(t) = x_1e^{x_2 t}$ to data $(\bm{t}, \bm{y})$
using a non-linear least squares fit.\\
The residual function is given by
$$
   r_i(\vx; t_i, y_i) = x_1 e^{x_2 t_i} - y_i.
$$
We can calculate the Jacobian and Hessian as
$$
   J_i(\vx; t_i, y_i) = \left(\begin{array}{cc}
      e^{x_2 t_i} &
      t_i x_1 e^{x_2 t_i}
      \end{array}\right)
$$
$$
   H_i(\vx; t_i, y_i) = \left(\begin{array}{cc}
      1                 & t_i e^{x_2 t_i}    \\
      t_i e^{x_2 t_i}   & t_i^2 e^{x_2 t_i}
   \end{array}\right)
$$
Given the data
\begin{center}
   \begin{tabular}{l|*{5}{r}}
      $i$   & 1 & 2 & 3  & 4  & 5 \\
      \hline
      $t_i$ & 1 & 2 & 4  & 5  & 8 \\
      $y_i$ & 3 & 4 & 6 & 11 & 20
   \end{tabular}
\end{center}
and initial guess $\vx = (2.5, 0.25)$, the following code performs the fit.

\verbatiminput{../example/C/nlls_example.c}


\end{document}
